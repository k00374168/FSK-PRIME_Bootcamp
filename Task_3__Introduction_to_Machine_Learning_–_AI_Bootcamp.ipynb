{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Task 3: Introduction to Machine Learning"
      ],
      "metadata": {
        "id": "L982FdumDCVn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 1: Setup & Dataset"
      ],
      "metadata": {
        "id": "gk9AwRFXDO6n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Task 1**: Load the Dataset\n",
        "\n",
        "*Instruction*: Load the preprocessed Titanic dataset (from the previous module or load again if needed). Separate it into features (`X`) and target (`y`, where target = `Survived`)."
      ],
      "metadata": {
        "id": "tG2LLFb4DSrf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('/content/sample_data/titanic.csv')\n",
        "x = df.drop('Survived', axis=1)\n",
        "y = df['Survived']\n",
        "\n",
        "x.head()\n",
        "y.head()\n"
      ],
      "metadata": {
        "id": "G6YtbgenDSWH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "5e25fe33-4586-4d11-89b7-f71020ba9068"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0\n",
              "1    1\n",
              "2    1\n",
              "3    1\n",
              "4    0\n",
              "Name: Survived, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Survived</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 2: Splitting the Data"
      ],
      "metadata": {
        "id": "03CKwCBtDzRL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Task 2**: Train/Test Split\n",
        "\n",
        "*Instruction*:\n",
        "\n",
        "Split the dataset into training and testing sets (80/20 split).\n"
      ],
      "metadata": {
        "id": "oh1W_9m5DuzF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Training set shape:\", x_train.shape, y_train.shape)\n",
        "print(\"Testing set shape:\", x_test.shape, y_test.shape)\n"
      ],
      "metadata": {
        "id": "SQTsWR6GDn6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "410838ff-8487-440e-d4b3-5115829d1926"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set shape: (709, 7) (709,)\n",
            "Testing set shape: (178, 7) (178,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 3: Train Your First Model"
      ],
      "metadata": {
        "id": "mVV1BgZvEE3a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Task 3**: Logistic Regression\n",
        "\n",
        "*Instruction*: Train a Logistic Regression model on the Titanic dataset. Display accuracy on both train and test sets.\n",
        "\n"
      ],
      "metadata": {
        "id": "opUK7Z7LEIr4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "df = pd.read_csv('/content/titanic.csv')\n",
        "\n",
        "df = df.rename(columns={\n",
        "    'Siblings/Spouses Aboard': 'SibSp',\n",
        "    'Parents/Children Aboard': 'Parch'\n",
        "})\n",
        "\n",
        "features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare']\n",
        "X = df[features]\n",
        "y = df['Survived']\n",
        "\n",
        "X = X.dropna()\n",
        "y = y[X.index]\n",
        "\n",
        "X = pd.get_dummies(X, columns=['Sex'], drop_first=True)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Calculate accuracy\n",
        "train_accuracy = model.score(X_train_scaled, y_train)\n",
        "test_accuracy = model.score(X_test_scaled, y_test)\n",
        "\n",
        "print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "id": "UW3FMdjQEEl3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "619e95aa-4b9b-45cb-8190-4095d4fb99ea"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy: 0.8152\n",
            "Test Accuracy: 0.7472\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 4: Model Evaluation"
      ],
      "metadata": {
        "id": "GNO0DPi3EpgF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Task 4**: Confusion Matrix & Classification Report\n",
        "\n",
        "*Instruction*: Evaluate the model using confusion matrix and classification report."
      ],
      "metadata": {
        "id": "W74DNGaJEtdj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "df = pd.read_csv('/content/titanic.csv')\n",
        "\n",
        "df = df.rename(columns={\n",
        "    'Siblings/Spouses Aboard': 'SibSp',\n",
        "    'Parents/Children Aboard': 'Parch'\n",
        "})\n",
        "\n",
        "features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare']\n",
        "X = df[features]\n",
        "y = df['Survived']\n",
        "\n",
        "X = X.dropna()\n",
        "y = y[X.index]\n",
        "\n",
        "# Encode categorical variable\n",
        "X = pd.get_dummies(X, columns=['Sex'], drop_first=True)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "class_report = classification_report(y_test, y_pred)\n",
        "\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(class_report)\n"
      ],
      "metadata": {
        "id": "aM8iWEAXEOmE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fd93345-6232-4c36-c7db-3a9cc0dfc883"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[96 15]\n",
            " [30 37]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.86      0.81       111\n",
            "           1       0.71      0.55      0.62        67\n",
            "\n",
            "    accuracy                           0.75       178\n",
            "   macro avg       0.74      0.71      0.72       178\n",
            "weighted avg       0.74      0.75      0.74       178\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 5: Try Another Model"
      ],
      "metadata": {
        "id": "yFxPFagsE9mS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Task 5**:  Random Forest Classifier\n",
        "\n",
        "*Instruction*: Train a `RandomForestClassifier` and compare its performance with Logistic Regression.\n"
      ],
      "metadata": {
        "id": "IZwIOzHXFD1a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "\n",
        "df = pd.read_csv('/content/titanic.csv')\n",
        "\n",
        "\n",
        "df = df.rename(columns={\n",
        "    'Siblings/Spouses Aboard': 'SibSp',\n",
        "    'Parents/Children Aboard': 'Parch'\n",
        "})\n",
        "\n",
        "features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare']\n",
        "X = df[features]\n",
        "y = df['Survived']\n",
        "\n",
        "X = X.dropna()\n",
        "y = y[X.index]\n",
        "\n",
        "X = pd.get_dummies(X, columns=['Sex'], drop_first=True)\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "log_model = LogisticRegression()\n",
        "log_model.fit(X_train_scaled, y_train)\n",
        "log_preds = log_model.predict(X_test_scaled)\n",
        "\n",
        "\n",
        "rf_model = RandomForestClassifier(random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "rf_preds = rf_model.predict(X_test)\n",
        "\n",
        "# Compare performance\n",
        "print(\"=== Logistic Regression ===\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, log_preds))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, log_preds))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, log_preds))\n",
        "\n",
        "print(\"\\n=== Random Forest Classifier ===\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, rf_preds))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, rf_preds))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, rf_preds))\n",
        "\n"
      ],
      "metadata": {
        "id": "VpUFTR1JFDWk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fa38dbb-90bb-476f-9fc8-5c546dbd867b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Logistic Regression ===\n",
            "Accuracy: 0.7471910112359551\n",
            "Confusion Matrix:\n",
            " [[96 15]\n",
            " [30 37]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.86      0.81       111\n",
            "           1       0.71      0.55      0.62        67\n",
            "\n",
            "    accuracy                           0.75       178\n",
            "   macro avg       0.74      0.71      0.72       178\n",
            "weighted avg       0.74      0.75      0.74       178\n",
            "\n",
            "\n",
            "=== Random Forest Classifier ===\n",
            "Accuracy: 0.7752808988764045\n",
            "Confusion Matrix:\n",
            " [[91 20]\n",
            " [20 47]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.82      0.82       111\n",
            "           1       0.70      0.70      0.70        67\n",
            "\n",
            "    accuracy                           0.78       178\n",
            "   macro avg       0.76      0.76      0.76       178\n",
            "weighted avg       0.78      0.78      0.78       178\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 6: Model Tuning"
      ],
      "metadata": {
        "id": "w-OY1jI5IaIB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Task 6**: Hyperparameter Tuning (GridSearch)\n",
        "\n",
        "*Instruction*:Use `GridSearchCV` to tune `n_estimators` and `max_depth` of the Random Forest model."
      ],
      "metadata": {
        "id": "xeBCcr3RIi-8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "categorical_cols = ['Name', 'Sex', 'Embarked', 'Cabin']\n",
        "\n",
        "label_encoders = {}\n",
        "for col in categorical_cols:\n",
        "    if col in X_train.columns:\n",
        "        label_encoders[col] = LabelEncoder()\n",
        "        label_encoders[col].fit(pd.concat([X_train[col], X_test[col]]).astype(str))\n",
        "        X_train[col] = label_encoders[col].transform(X_train[col].astype(str))\n",
        "        X_test[col] = label_encoders[col].transform(X_test[col].astype(str))\n",
        "\n",
        "# Define the parameter grid\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [5, 10, 15]\n",
        "}\n",
        "\n",
        "rf_model = RandomForestClassifier(random_state=42)\n",
        "\n",
        "\n",
        "grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "best_params = grid_search.best_params_\n",
        "print(f\"Best Hyperparameters: {best_params}\")\n",
        "\n",
        "best_rf_model = grid_search.best_estimator_\n",
        "\n",
        "# Make predictions using the best model\n",
        "y_pred_rf = best_rf_model.predict(X_test)\n",
        "\n",
        "# Evaluate the best model\n",
        "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
        "print(f\"Accuracy of the best Random Forest model: {accuracy_rf}\")\n",
        "print(classification_report(y_test, y_pred_rf))\n"
      ],
      "metadata": {
        "id": "gSza6VScIakN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "608f3f13-be78-4088-ce4b-be2fec974a87"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters: {'max_depth': 10, 'n_estimators': 200}\n",
            "Accuracy of the best Random Forest model: 0.8146067415730337\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.88      0.86       111\n",
            "           1       0.78      0.70      0.74        67\n",
            "\n",
            "    accuracy                           0.81       178\n",
            "   macro avg       0.81      0.79      0.80       178\n",
            "weighted avg       0.81      0.81      0.81       178\n",
            "\n"
          ]
        }
      ]
    }
  ]
}